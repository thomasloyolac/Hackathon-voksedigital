{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad36b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e485e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train (1).csv')\n",
    "dft=pd.read_csv('test (1).csv')\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8eb853",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingvalues=['ID','major_occ_code','house_1yr_ago','under18','unemp_reason','woker_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3461436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(missingvalues,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c343cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=dft.drop(missingvalues,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8af1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income']=df['income'].replace({'More than 50K $':0,'Less than 50K $':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76022d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['year_of_poll', 'currently_enrolled', 'labour_union',\n",
    "       'income_filled'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3354e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft=dft.drop(['year_of_poll', 'currently_enrolled', 'labour_union',\n",
    "       'income_filled'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3cb4584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['own_self_emp', 'veteran benefits', 'race', 'father_country', 'educ',\n",
       "       'house_stat', 'major_ind_code', 'self_country', 'age', 'mother_country',\n",
       "       'house_summary', 'gender', 'hisp_origin', 'gains', 'dividends',\n",
       "       'marriage_status', 'losses', 'employer_of', 'weeks_worked',\n",
       "       'hourly_wage', 'citizenship', 'fed_liability', 'full_partime_job',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "841bf63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['own_self_emp', 'veteran benefits', 'race', 'father_country', 'educ',\n",
       "       'house_stat', 'major_ind_code', 'self_country', 'age', 'mother_country',\n",
       "       'house_summary', 'gender', 'hisp_origin', 'gains', 'dividends',\n",
       "       'marriage_status', 'losses', 'employer_of', 'weeks_worked',\n",
       "       'hourly_wage', 'citizenship', 'fed_liability', 'full_partime_job'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41824a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "col=['race', 'father_country', 'house_stat', 'major_ind_code', 'self_country', 'mother_country',\n",
    "       'house_summary',  'hisp_origin', 'marriage_status', 'citizenship', 'fed_liability', 'full_partime_job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a931f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "    df[i]=df[i].map(df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d512d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88078,  1174, 10763,  3050,  1935], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1551c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col:\n",
    "    dft[i]=dft[i].map(df1[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c7bb3e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([88078, 10763,  1935,  3050,  1174], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf668975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a7452d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe=OrdinalEncoder(categories=[[' Children',' Less than 1st grade',' 1st 2nd 3rd or 4th grade',' 5th or 6th grade',' 7th and 8th grade',' 9th grade',' 10th grade', ' 11th grade',' 12th grade no diploma',' High school graduate',' Prof school degree (MD DDS DVM LLB JD)',' Some college but no degree',' Bachelors degree(BA AB BS)',' Associates degree-academic program',' Associates degree-occup /vocational',' Masters degree(MA MS MEng MEd MSW MBA)',' Doctorate degree(PhD EdD)']])\n",
    "df['educ']=oe.fit_transform(df[['educ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8db3df07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.,  0., 11.,  9.,  6., 10., 12.,  4.,  3.,  5.,  7., 15., 14.,\n",
       "        2.,  1.,  8., 16.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['educ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b18adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['educ']=oe.fit_transform(dft[['educ']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02711651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 12.,  4.,  9., 16.,  0.,  6.,  5.,  8.,  2.,  7., 15., 14.,\n",
       "       10., 13.,  3.,  1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['educ'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11e97f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['house_stat']=df['house_stat'].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e469783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['house_stat']=dft['house_stat'].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd87b57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.8081e+04, 1.1728e+04, 1.0800e+02, 3.2240e+03, 2.1940e+04,\n",
       "       2.6380e+04, 5.4200e+02, 6.3200e+03, 5.4700e+02, 3.8800e+02,\n",
       "       3.9000e+02, 3.1600e+02, 3.4800e+02, 3.0800e+02, 9.9700e+02,\n",
       "       9.2900e+02, 6.4000e+01, 9.8000e+02, 3.8600e+02, 3.0000e+00,\n",
       "       3.5000e+02, 1.9500e+02, 1.4000e+01, 4.6000e+01, 2.3000e+01,\n",
       "       4.5000e+01, 5.0000e+00, 2.0000e+00, 1.9000e+01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['house_stat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "556d1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].replace({'M':0,'F':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cc57ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['gender']=dft['gender'].replace({'M':0,'F':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "daa8faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['64168.0', '21083.0', '14051.0', 'nan', '654.0', '1737.0',\n",
       "       '1185.0', '450.0', '280.0'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_partime_job'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b27d18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21083., 64168., 14051.,  1185.,   654.,    nan,  1737.,   280.,\n",
       "         450.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['full_partime_job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f36b95fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_partime_job\n",
      "280.0      38.0\n",
      "450.0      23.0\n",
      "654.0      43.5\n",
      "1185.0     36.0\n",
      "1737.0     40.0\n",
      "14051.0    60.0\n",
      "21083.0    40.0\n",
      "64168.0    26.0\n",
      "Name: age, dtype: float64----------"
     ]
    }
   ],
   "source": [
    "i='full_partime_job'\n",
    "j='age'\n",
    "print(df.groupby(i)[j].median(),end='-'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "224bef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpj=df[df['full_partime_job']=='nan'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "50a1033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_partime_job']=df['full_partime_job'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9723ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['age']=dft['age'].fillna(dft.groupby('marriage_status')['age'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de83d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02bf4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fpj:\n",
    "    if df.loc[i,'age']<=23:\n",
    "        df.loc[i,'full_partime_job']='450'\n",
    "    elif df.loc[i,'age']>23 and  df.loc[i,'age']<=30:\n",
    "        df.loc[i,'full_partime_job']='64168'\n",
    "    elif df.loc[i,'age']>30 and  df.loc[i,'age']<=38:\n",
    "        df.loc[i,'full_partime_job']='280'\n",
    "    elif df.loc[i,'age']>38 and df.loc[i,'age']<=40:\n",
    "        df.loc[i,'full_partime_job']='21083'\n",
    "    elif df.loc[i,'age']>40 and df.loc[i,'age']<=46:\n",
    "        df.loc[i,'full_partime_job']='654'\n",
    "    else:\n",
    "        df.loc[i,'full_partime_job']='14051'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea31cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>own_self_emp</th>\n",
       "      <th>veteran benefits</th>\n",
       "      <th>race</th>\n",
       "      <th>father_country</th>\n",
       "      <th>educ</th>\n",
       "      <th>house_stat</th>\n",
       "      <th>major_ind_code</th>\n",
       "      <th>self_country</th>\n",
       "      <th>age</th>\n",
       "      <th>mother_country</th>\n",
       "      <th>...</th>\n",
       "      <th>dividends</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>losses</th>\n",
       "      <th>employer_of</th>\n",
       "      <th>weeks_worked</th>\n",
       "      <th>hourly_wage</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>fed_liability</th>\n",
       "      <th>full_partime_job</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [own_self_emp, veteran benefits, race, father_country, educ, house_stat, major_ind_code, self_country, age, mother_country, house_summary, gender, hisp_origin, gains, dividends, marriage_status, losses, employer_of, weeks_worked, hourly_wage, citizenship, fed_liability, full_partime_job, income]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['full_partime_job']=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db338c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['full_partime_job']=df['full_partime_job'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2756e3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64168., 21083., 14051.,   450.,   654.,  1737.,  1185.,   280.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_partime_job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e75308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['full_partime_job']=dft['full_partime_job'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb3160f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpjt=dft[dft['full_partime_job']=='nan'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "259c6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fpjt:\n",
    "    if dft.loc[i,'age']<=23:\n",
    "        dft.loc[i,'full_partime_job']='450'\n",
    "    elif dft.loc[i,'age']>23 and  dft.loc[i,'age']<=30:\n",
    "        dft.loc[i,'full_partime_job']='64168'\n",
    "    elif dft.loc[i,'age']>30 and  dft.loc[i,'age']<=38:\n",
    "        dft.loc[i,'full_partime_job']='280'\n",
    "    elif dft.loc[i,'age']>38 and dft.loc[i,'age']<=40:\n",
    "        dft.loc[i,'full_partime_job']='21083'\n",
    "    elif dft.loc[i,'age']>40 and dft.loc[i,'age']<=46:\n",
    "        dft.loc[i,'full_partime_job']='654'\n",
    "    else:\n",
    "        dft.loc[i,'full_partime_job']='14051'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5fc948f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['full_partime_job']=dft['full_partime_job'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "92d6f723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21083., 64168., 14051.,  1185.,   654.,  1737.,   450.,   280.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft['full_partime_job'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ba62db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('income',1)\n",
    "y=df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c4e8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1085e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3ae196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>own_self_emp</th>\n",
       "      <th>veteran benefits</th>\n",
       "      <th>race</th>\n",
       "      <th>father_country</th>\n",
       "      <th>educ</th>\n",
       "      <th>house_stat</th>\n",
       "      <th>major_ind_code</th>\n",
       "      <th>self_country</th>\n",
       "      <th>age</th>\n",
       "      <th>mother_country</th>\n",
       "      <th>...</th>\n",
       "      <th>gains</th>\n",
       "      <th>dividends</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>losses</th>\n",
       "      <th>employer_of</th>\n",
       "      <th>weeks_worked</th>\n",
       "      <th>hourly_wage</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>fed_liability</th>\n",
       "      <th>full_partime_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886072</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.939421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.114748</td>\n",
       "      <td>0.090206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886072</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   own_self_emp  veteran benefits  race  father_country    educ  house_stat  \\\n",
       "0           0.0               1.0   1.0        1.000000  0.8125    1.000000   \n",
       "1           0.0               0.0   1.0        0.002365  0.0000    0.939421   \n",
       "2           0.0               1.0   1.0        1.000000  0.6875    0.114748   \n",
       "3           0.0               1.0   0.0        1.000000  0.5625    1.000000   \n",
       "4           0.0               1.0   1.0        1.000000  0.5625    1.000000   \n",
       "\n",
       "   major_ind_code  self_country       age  mother_country  ...  gains  \\\n",
       "0        0.055455           1.0  0.446809             1.0  ...    0.0   \n",
       "1        1.000000           1.0  0.106383             1.0  ...    0.0   \n",
       "2        0.090206           1.0  0.489362             1.0  ...    0.0   \n",
       "3        0.034638           1.0  0.372340             1.0  ...    0.0   \n",
       "4        0.034638           1.0  0.648936             1.0  ...    0.0   \n",
       "\n",
       "   dividends  marriage_status  losses  employer_of  weeks_worked  hourly_wage  \\\n",
       "0        0.0         0.971415     0.0     0.166667           1.0          0.0   \n",
       "1        0.0         1.000000     0.0     0.000000           0.0          0.0   \n",
       "2        0.0         0.141019     0.0     1.000000           1.0          0.0   \n",
       "3        0.0         0.971415     0.0     0.333333           1.0          0.0   \n",
       "4        0.0         0.141019     0.0     0.500000           1.0          0.0   \n",
       "\n",
       "   citizenship  fed_liability  full_partime_job  \n",
       "0          1.0       0.886072               1.0  \n",
       "1          1.0       1.000000               1.0  \n",
       "2          1.0       0.470511               1.0  \n",
       "3          1.0       0.886072               1.0  \n",
       "4          1.0       0.470511               1.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled=scaler.fit_transform(x)\n",
    "scaled_df=pd.DataFrame(scaled,columns=x.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e699666c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>own_self_emp</th>\n",
       "      <th>veteran benefits</th>\n",
       "      <th>race</th>\n",
       "      <th>father_country</th>\n",
       "      <th>educ</th>\n",
       "      <th>house_stat</th>\n",
       "      <th>major_ind_code</th>\n",
       "      <th>self_country</th>\n",
       "      <th>age</th>\n",
       "      <th>mother_country</th>\n",
       "      <th>...</th>\n",
       "      <th>gains</th>\n",
       "      <th>dividends</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>losses</th>\n",
       "      <th>employer_of</th>\n",
       "      <th>weeks_worked</th>\n",
       "      <th>hourly_wage</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>fed_liability</th>\n",
       "      <th>full_partime_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.971415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886072</td>\n",
       "      <td>0.325617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.417607</td>\n",
       "      <td>0.046442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.114748</td>\n",
       "      <td>0.069465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024557</td>\n",
       "      <td>0.470511</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   own_self_emp  veteran benefits  race  father_country    educ  house_stat  \\\n",
       "0           0.0               1.0   1.0        1.000000  0.6875    1.000000   \n",
       "1           0.0               1.0   1.0        1.000000  0.7500    0.417607   \n",
       "2           0.0               1.0   1.0        1.000000  0.2500    0.003775   \n",
       "3           1.0               1.0   1.0        1.000000  0.5625    0.114748   \n",
       "4           0.0               1.0   1.0        0.001219  1.0000    1.000000   \n",
       "\n",
       "   major_ind_code  self_country       age  mother_country  ...  gains  \\\n",
       "0        0.069465      1.000000  0.340426        1.000000  ...    0.0   \n",
       "1        0.046442      1.000000  0.542553        1.000000  ...    0.0   \n",
       "2        1.000000      1.000000  0.744681        1.000000  ...    0.0   \n",
       "3        0.069465      1.000000  0.265957        1.000000  ...    0.0   \n",
       "4        0.045160      0.000699  0.691489        0.000925  ...    0.0   \n",
       "\n",
       "   dividends  marriage_status  losses  employer_of  weeks_worked  hourly_wage  \\\n",
       "0      0.000         0.971415     0.0     1.000000           1.0          0.0   \n",
       "1      0.001         1.000000     0.0     1.000000           1.0          0.0   \n",
       "2      0.000         0.114095     0.0     0.000000           0.0          0.0   \n",
       "3      0.000         1.000000     0.0     0.333333           1.0          0.0   \n",
       "4      0.000         0.114095     0.0     1.000000           1.0          0.0   \n",
       "\n",
       "   citizenship  fed_liability  full_partime_job  \n",
       "0     1.000000       0.886072          0.325617  \n",
       "1     1.000000       0.470511          1.000000  \n",
       "2     1.000000       1.000000          1.000000  \n",
       "3     1.000000       0.470511          1.000000  \n",
       "4     0.024557       0.470511          1.000000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledt=scaler.transform(xt)\n",
    "scaled_dft=pd.DataFrame(scaledt,columns=xt.columns)\n",
    "scaled_dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91f47775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "691907d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2dd969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6377333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.67      0.15      5054\n",
      "           1       0.97      0.64      0.77     99946\n",
      "\n",
      "    accuracy                           0.64    105000\n",
      "   macro avg       0.53      0.65      0.46    105000\n",
      "weighted avg       0.93      0.64      0.74    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(scaled_df,y)\n",
    "ypred=lr.predict(scaled_df)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "917b92e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102095238095238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     32252\n",
      "           1       0.99      0.88      0.93     72748\n",
      "\n",
      "    accuracy                           0.91    105000\n",
      "   macro avg       0.89      0.93      0.90    105000\n",
      "weighted avg       0.92      0.91      0.91    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(scaled_df,y)\n",
    "ypred=rf.predict(scaled_df)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1b58765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredt=rf.predict(scaled_dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "524a0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredrf=pd.DataFrame(ypredt)\n",
    "ypredrf.to_csv('5yp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5384d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a175b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:44:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.6700857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.76      0.30      9609\n",
      "           1       0.97      0.66      0.78     95391\n",
      "\n",
      "    accuracy                           0.67    105000\n",
      "   macro avg       0.58      0.71      0.54    105000\n",
      "weighted avg       0.89      0.67      0.74    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg.fit(scaled_df,y)\n",
    "ypred=xg.predict(scaled_df)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "98091b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm=SMOTE()\n",
    "xre,yre=sm.fit_resample(scaled_df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2714452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg1=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2aba9101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:48:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.6842290721902194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.88      0.57     31470\n",
      "           1       0.94      0.62      0.75     99074\n",
      "\n",
      "    accuracy                           0.68    130544\n",
      "   macro avg       0.68      0.75      0.66    130544\n",
      "weighted avg       0.82      0.68      0.71    130544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg1.fit(xre,yre)\n",
    "ypred=xg1.predict(xre)\n",
    "print(accuracy_score(ypred,yre))\n",
    "print(classification_report(ypred,yre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f674d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ff505a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8962955018997426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89     56856\n",
      "           1       0.96      0.85      0.90     73688\n",
      "\n",
      "    accuracy                           0.90    130544\n",
      "   macro avg       0.90      0.90      0.90    130544\n",
      "weighted avg       0.90      0.90      0.90    130544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf1.fit(xre,yre)\n",
    "ypred=rf1.predict(xre)\n",
    "print(accuracy_score(ypred,yre))\n",
    "print(classification_report(ypred,yre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e95c45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredrf1=rf1.predict(scaled_dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bb7f9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredrf2=pd.DataFrame(ypredrf1)\n",
    "ypredrf2.to_csv('6yp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d6e77976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00838921, 0.01649626, 0.03053483, 0.06267815,\n",
       "       0.01507169, 0.0705126 , 0.02372331, 0.11445078, 0.03042931,\n",
       "       0.01484843, 0.00583148, 0.02435513, 0.01413474, 0.0216393 ,\n",
       "       0.02070265, 0.00149136, 0.02493536, 0.03284157, 0.00897344,\n",
       "       0.01757927, 0.01484499, 0.01676325])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutin=mutual_info_classif(xre,yre)\n",
    "mutin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03bd1d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 0.114451\n",
       "major_ind_code      0.070513\n",
       "educ                0.062678\n",
       "weeks_worked        0.032842\n",
       "father_country      0.030535\n",
       "mother_country      0.030429\n",
       "employer_of         0.024935\n",
       "hisp_origin         0.024355\n",
       "self_country        0.023723\n",
       "dividends           0.021639\n",
       "marriage_status     0.020703\n",
       "citizenship         0.017579\n",
       "full_partime_job    0.016763\n",
       "race                0.016496\n",
       "house_stat          0.015072\n",
       "house_summary       0.014848\n",
       "fed_liability       0.014845\n",
       "gains               0.014135\n",
       "hourly_wage         0.008973\n",
       "veteran benefits    0.008389\n",
       "gender              0.005831\n",
       "losses              0.001491\n",
       "own_self_emp        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutin=pd.Series(mutin)\n",
    "mutin.index=scaled_df.columns\n",
    "mutin.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43b956af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mutin.sort_values(ascending=False).plot.bar(figsize=(20,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "930f14d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff5663ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race', 'father_country', 'educ', 'house_stat', 'major_ind_code',\n",
       "       'self_country', 'age', 'mother_country', 'house_summary', 'hisp_origin',\n",
       "       'gains', 'dividends', 'marriage_status', 'employer_of', 'weeks_worked',\n",
       "       'citizenship', 'fed_liability', 'full_partime_job'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "besfe=SelectKBest(mutual_info_classif,k=18)\n",
    "besfe.fit(xre,yre)\n",
    "scaled_df.columns[besfe.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ac3a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbefe=scaled_df[['race', 'father_country', 'educ', 'house_stat', 'major_ind_code',\n",
    "       'self_country', 'age', 'mother_country', 'house_summary', 'hisp_origin',\n",
    "       'gains', 'dividends', 'marriage_status', 'employer_of', 'weeks_worked',\n",
    "       'citizenship', 'fed_liability', 'full_partime_job']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dda8c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtbefe=scaled_dft[['race', 'father_country', 'educ', 'house_stat', 'major_ind_code',\n",
    "       'self_country', 'age', 'mother_country', 'house_summary', 'hisp_origin',\n",
    "       'gains', 'dividends', 'marriage_status', 'employer_of', 'weeks_worked',\n",
    "       'citizenship', 'fed_liability', 'full_partime_job']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dbdb7d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88636015443069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88     55469\n",
      "           1       0.96      0.84      0.89     75075\n",
      "\n",
      "    accuracy                           0.89    130544\n",
      "   macro avg       0.89      0.90      0.89    130544\n",
      "weighted avg       0.90      0.89      0.89    130544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf4=RandomForestClassifier()\n",
    "rf4.fit(xrebefe,yre)\n",
    "ypred=rf4.predict(xrebefe)\n",
    "print(accuracy_score(ypred,yre))\n",
    "print(classification_report(ypred,yre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "837fc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredxre=rf4.predict(xtbefe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eb93b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy=pd.DataFrame(ypredxre)\n",
    "yyy.to_csv('6yp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5d664b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "xgg1=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5d4f1f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.628722882706214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.76      0.51     32864\n",
      "           1       0.88      0.59      0.70     97680\n",
      "\n",
      "    accuracy                           0.63    130544\n",
      "   macro avg       0.63      0.67      0.60    130544\n",
      "weighted avg       0.75      0.63      0.65    130544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgg1.fit(xrebefe,yre)\n",
    "ypred=xgg1.predict(xrebefe)\n",
    "print(accuracy_score(ypred,yre))\n",
    "print(classification_report(ypred,yre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5f95c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "374915ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5460610981737958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.55      0.51     56221\n",
      "           1       0.62      0.54      0.58     74323\n",
      "\n",
      "    accuracy                           0.55    130544\n",
      "   macro avg       0.55      0.55      0.54    130544\n",
      "weighted avg       0.56      0.55      0.55    130544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(xrebefe,yre)\n",
    "ypred=lr.predict(xrebefe)\n",
    "print(accuracy_score(ypred,yre))\n",
    "print(classification_report(ypred,yre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "19eac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "df8cce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6329428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.72      0.09      2737\n",
      "           1       0.99      0.63      0.77    102263\n",
      "\n",
      "    accuracy                           0.63    105000\n",
      "   macro avg       0.52      0.67      0.43    105000\n",
      "weighted avg       0.96      0.63      0.75    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(xbefe,y)\n",
    "ypred=lr.predict(xbefe)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1cf0769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2ba83a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8990095238095238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85     31624\n",
      "           1       0.98      0.87      0.92     73376\n",
      "\n",
      "    accuracy                           0.90    105000\n",
      "   macro avg       0.87      0.92      0.89    105000\n",
      "weighted avg       0.92      0.90      0.90    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(xbefe,y)\n",
    "ypred=rf.predict(xbefe)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6f302f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4ad4669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "17ce2e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.63220952        nan 0.63226667        nan 0.63218095        nan\n",
      " 0.63229524        nan 0.63215238        nan 0.63219048        nan\n",
      " 0.63220952        nan 0.63224762        nan 0.63213333        nan\n",
      " 0.63199048        nan 0.63217143 0.63217143 0.63217143 0.6321619\n",
      " 0.63229524 0.63230476 0.63231429 0.63230476 0.63217143 0.63217143\n",
      " 0.6322     0.63221905 0.63220952 0.63221905 0.6322     0.63221905\n",
      " 0.63222857 0.63222857 0.6322381  0.63221905 0.63222857 0.63222857\n",
      " 0.63220952 0.63220952 0.63221905 0.63221905 0.63220952 0.63220952\n",
      " 0.63221905 0.63221905 0.63221905 0.63218095 0.63221905 0.63221905\n",
      " 0.63220952 0.63218095 0.63221905 0.63221905 0.63220952 0.63218095\n",
      " 0.62458095 0.62688571 0.62799048 0.62781905 0.62838095 0.62790476\n",
      " 0.6262381  0.62740952 0.62778095 0.62741905 0.62804762 0.62766667\n",
      " 0.6244     0.62735238 0.62584762 0.62841905 0.62729524 0.62835238\n",
      " 0.63286667 0.63405714 0.63393333 0.6328381  0.63367619 0.63422857\n",
      " 0.63332381 0.63387619 0.63401905 0.63414286 0.63407619 0.63390476\n",
      " 0.63521905 0.63382857 0.63377143 0.63144762 0.63377143 0.63408571\n",
      " 0.6364381  0.63730476 0.6370381  0.63717143 0.63702857 0.637\n",
      " 0.63747619 0.63640952 0.63744762 0.63592381 0.63714286 0.6371619\n",
      " 0.63601905 0.63724762 0.63707619 0.63786667 0.63724762 0.6370381\n",
      " 0.62464762 0.62680952 0.62738095 0.62826667 0.62648571 0.62708571\n",
      " 0.62486667 0.6281619  0.62808571 0.6253619  0.62545714 0.62837143\n",
      " 0.62555238 0.62719048 0.6266381  0.62582857 0.62568571 0.62775238\n",
      " 0.63247619 0.6334381  0.63384762 0.63268571 0.6334381  0.63377143\n",
      " 0.63164762 0.63394286 0.63399048 0.63327619 0.6338     0.63378095\n",
      " 0.63308571 0.63387619 0.63372381 0.63451429 0.63386667 0.63406667\n",
      " 0.63842857 0.63892381 0.63879048 0.63845714 0.63800952 0.63849524\n",
      " 0.63929524 0.63814286 0.63886667 0.63781905 0.63874286 0.63884762\n",
      " 0.63749524 0.63831429 0.63866667 0.63862857 0.6384     0.6392\n",
      " 0.62339048 0.62780952 0.62779048 0.62629524 0.6249619  0.62758095\n",
      " 0.62714286 0.62721905 0.62698095 0.62694286 0.62802857 0.62794286\n",
      " 0.62331429 0.62521905 0.62739048 0.62482857 0.62641905 0.62789524\n",
      " 0.63417143 0.63413333 0.63375238 0.63254286 0.63326667 0.63397143\n",
      " 0.63280952 0.63482857 0.63388571 0.63217143 0.63368571 0.63393333\n",
      " 0.63293333 0.63350476 0.63404762 0.63518095 0.63354286 0.63392381\n",
      " 0.63925714 0.63855238 0.6387619  0.63717143 0.63869524 0.63897143\n",
      " 0.63695238 0.63865714 0.63895238 0.6366381  0.6378     0.63867619\n",
      " 0.63824762 0.63893333 0.63870476 0.63807619 0.6383619  0.63906667\n",
      " 0.62392381 0.62839048 0.62715238 0.62410476 0.62810476 0.62755238\n",
      " 0.6244381  0.6262381  0.62730476 0.62338095 0.62507619 0.62691429\n",
      " 0.6238     0.62714286 0.62765714 0.62577143 0.62553333 0.628\n",
      " 0.63346667 0.63349524 0.63370476 0.63422857 0.63434286 0.63386667\n",
      " 0.63304762 0.63370476 0.63364762 0.63152381 0.63340952 0.63402857\n",
      " 0.63365714 0.63468571 0.6341619  0.63361905 0.63487619 0.63370476\n",
      " 0.63853333 0.63852381 0.63855238 0.63940952 0.63813333 0.63877143\n",
      " 0.6376381  0.63853333 0.63879048 0.63842857 0.63871429 0.63859048\n",
      " 0.63795238 0.63881905 0.63884762 0.63869524 0.63871429 0.63907619\n",
      " 0.62735238 0.62859048 0.62762857 0.62807619 0.62640952 0.62784762\n",
      " 0.62425714 0.62747619 0.62650476 0.6272     0.62632381 0.62809524\n",
      " 0.62428571 0.62679048 0.62751429 0.62359048 0.62700952 0.62680952\n",
      " 0.63135238 0.63372381 0.6341619  0.63470476 0.63438095 0.63392381\n",
      " 0.63233333 0.63354286 0.63374286 0.63338095 0.63414286 0.63374286\n",
      " 0.63211429 0.63448571 0.63370476 0.63366667 0.63311429 0.63398095\n",
      " 0.63980952 0.63845714 0.63886667 0.637      0.63873333 0.63894286\n",
      " 0.6382     0.63869524 0.6388381  0.63691429 0.63794286 0.63907619\n",
      " 0.63920952 0.63838095 0.63840952 0.63745714 0.6381619  0.6389619\n",
      " 0.62792381 0.62733333 0.62647619 0.62500952 0.62640952 0.62784762\n",
      " 0.62404762 0.62727619 0.62741905 0.62440952 0.6286     0.62759048\n",
      " 0.6252381  0.62637143 0.62768571 0.62721905 0.62771429 0.6272\n",
      " 0.63232381 0.63392381 0.63391429 0.63335238 0.63385714 0.63395238\n",
      " 0.63274286 0.63400952 0.63388571 0.63257143 0.63433333 0.63400952\n",
      " 0.63268571 0.63454286 0.63360952 0.63359048 0.63385714 0.63385714\n",
      " 0.63729524 0.6382     0.63882857 0.63877143 0.6388     0.63885714\n",
      " 0.63802857 0.63828571 0.63862857 0.63744762 0.63927619 0.63899048\n",
      " 0.63790476 0.6392     0.63902857 0.63810476 0.63886667 0.63908571]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2','l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(xbefe,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f900bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier',\n",
      "                 RandomForestClassifier(max_depth=30, max_leaf_nodes=10,\n",
      "                                        n_estimators=10))])\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "68dab9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(max_depth=32, max_leaf_nodes=7,\n",
    "                                        n_estimators=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c2e0d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c21b2676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8990095238095238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85     31598\n",
      "           1       0.98      0.87      0.92     73402\n",
      "\n",
      "    accuracy                           0.90    105000\n",
      "   macro avg       0.87      0.92      0.89    105000\n",
      "weighted avg       0.92      0.90      0.90    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.fit(xbefe,y)\n",
    "ypred=rf.predict(xbefe)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "360289f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dt=pd.DataFrame(scaled_df)\n",
    "scaled_dt.to_csv('scaled_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bcf220b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_dtt=pd.DataFrame(scaled_dft)\n",
    "scaled_dtt.to_csv('scaled_dft.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5ec46106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pc=PCA(n_components=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b66a7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaled_df\n",
    "y=df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7e9b53bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>own_self_emp</th>\n",
       "      <th>veteran benefits</th>\n",
       "      <th>race</th>\n",
       "      <th>father_country</th>\n",
       "      <th>educ</th>\n",
       "      <th>house_stat</th>\n",
       "      <th>major_ind_code</th>\n",
       "      <th>self_country</th>\n",
       "      <th>age</th>\n",
       "      <th>mother_country</th>\n",
       "      <th>...</th>\n",
       "      <th>gains</th>\n",
       "      <th>dividends</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>losses</th>\n",
       "      <th>employer_of</th>\n",
       "      <th>weeks_worked</th>\n",
       "      <th>hourly_wage</th>\n",
       "      <th>citizenship</th>\n",
       "      <th>fed_liability</th>\n",
       "      <th>full_partime_job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88078</td>\n",
       "      <td>83720</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28081.0</td>\n",
       "      <td>3705</td>\n",
       "      <td>93022</td>\n",
       "      <td>32.0</td>\n",
       "      <td>84324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93024</td>\n",
       "      <td>35315</td>\n",
       "      <td>21083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88078</td>\n",
       "      <td>83720</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11728.0</td>\n",
       "      <td>2484</td>\n",
       "      <td>93022</td>\n",
       "      <td>51.0</td>\n",
       "      <td>84324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>45521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93024</td>\n",
       "      <td>19729</td>\n",
       "      <td>64168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88078</td>\n",
       "      <td>83720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>53055</td>\n",
       "      <td>93022</td>\n",
       "      <td>70.0</td>\n",
       "      <td>84324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93024</td>\n",
       "      <td>39588</td>\n",
       "      <td>64168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>88078</td>\n",
       "      <td>83720</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3224.0</td>\n",
       "      <td>3705</td>\n",
       "      <td>93022</td>\n",
       "      <td>25.0</td>\n",
       "      <td>84324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93024</td>\n",
       "      <td>19729</td>\n",
       "      <td>64168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88078</td>\n",
       "      <td>113</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28081.0</td>\n",
       "      <td>2416</td>\n",
       "      <td>77</td>\n",
       "      <td>65.0</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3095</td>\n",
       "      <td>19729</td>\n",
       "      <td>64168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   own_self_emp  veteran benefits   race  father_country  educ  house_stat  \\\n",
       "0             0                 2  88078           83720  11.0     28081.0   \n",
       "1             0                 2  88078           83720  12.0     11728.0   \n",
       "2             0                 2  88078           83720   4.0       108.0   \n",
       "3             2                 2  88078           83720   9.0      3224.0   \n",
       "4             0                 2  88078             113  16.0     28081.0   \n",
       "\n",
       "   major_ind_code  self_country   age  mother_country  ...  gains  dividends  \\\n",
       "0            3705         93022  32.0           84324  ...    0.0        0.0   \n",
       "1            2484         93022  51.0           84324  ...    0.0      120.0   \n",
       "2           53055         93022  70.0           84324  ...    0.0        0.0   \n",
       "3            3705         93022  25.0           84324  ...    0.0        0.0   \n",
       "4            2416            77  65.0              96  ...    0.0        0.0   \n",
       "\n",
       "   marriage_status  losses  employer_of  weeks_worked  hourly_wage  \\\n",
       "0            44230     0.0            6            47          0.0   \n",
       "1            45521     0.0            6            47          0.0   \n",
       "2             5510     0.0            0             0          0.0   \n",
       "3            45521     0.0            2            47          0.0   \n",
       "4             5510     0.0            6            47          0.0   \n",
       "\n",
       "   citizenship  fed_liability  full_partime_job  \n",
       "0        93024          35315           21083.0  \n",
       "1        93024          19729           64168.0  \n",
       "2        93024          39588           64168.0  \n",
       "3        93024          19729           64168.0  \n",
       "4         3095          19729           64168.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "50e7711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641140</td>\n",
       "      <td>-0.388118</td>\n",
       "      <td>-0.615552</td>\n",
       "      <td>0.110333</td>\n",
       "      <td>-0.309614</td>\n",
       "      <td>-0.119393</td>\n",
       "      <td>0.167396</td>\n",
       "      <td>-0.314128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.194209</td>\n",
       "      <td>0.357713</td>\n",
       "      <td>-0.762247</td>\n",
       "      <td>-0.144182</td>\n",
       "      <td>-0.045037</td>\n",
       "      <td>-0.436716</td>\n",
       "      <td>-0.130610</td>\n",
       "      <td>0.491469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.021508</td>\n",
       "      <td>-0.306437</td>\n",
       "      <td>-0.163658</td>\n",
       "      <td>-0.080441</td>\n",
       "      <td>0.884010</td>\n",
       "      <td>-0.404210</td>\n",
       "      <td>0.623486</td>\n",
       "      <td>0.213678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595730</td>\n",
       "      <td>-0.302108</td>\n",
       "      <td>-0.666638</td>\n",
       "      <td>-0.086495</td>\n",
       "      <td>-0.143666</td>\n",
       "      <td>0.756630</td>\n",
       "      <td>0.462016</td>\n",
       "      <td>-0.096063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.802719</td>\n",
       "      <td>-0.323535</td>\n",
       "      <td>0.440277</td>\n",
       "      <td>-0.061987</td>\n",
       "      <td>-0.578489</td>\n",
       "      <td>-0.213220</td>\n",
       "      <td>0.640079</td>\n",
       "      <td>0.276364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.641140 -0.388118 -0.615552  0.110333 -0.309614 -0.119393  0.167396   \n",
       "1 -1.194209  0.357713 -0.762247 -0.144182 -0.045037 -0.436716 -0.130610   \n",
       "2  1.021508 -0.306437 -0.163658 -0.080441  0.884010 -0.404210  0.623486   \n",
       "3  0.595730 -0.302108 -0.666638 -0.086495 -0.143666  0.756630  0.462016   \n",
       "4  0.802719 -0.323535  0.440277 -0.061987 -0.578489 -0.213220  0.640079   \n",
       "\n",
       "          8  \n",
       "0 -0.314128  \n",
       "1  0.491469  \n",
       "2  0.213678  \n",
       "3 -0.096063  \n",
       "4  0.276364  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp=pc.fit_transform(x)\n",
    "xpc=pd.DataFrame(dfp,columns=['1','2','3','4','5','6','7','8'])\n",
    "xpc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5d835cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.005661</td>\n",
       "      <td>-0.383383</td>\n",
       "      <td>-0.594069</td>\n",
       "      <td>0.071181</td>\n",
       "      <td>-0.250360</td>\n",
       "      <td>0.125830</td>\n",
       "      <td>-0.339176</td>\n",
       "      <td>0.077826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997704</td>\n",
       "      <td>-0.329294</td>\n",
       "      <td>0.353681</td>\n",
       "      <td>-0.444899</td>\n",
       "      <td>-0.176497</td>\n",
       "      <td>-0.192101</td>\n",
       "      <td>0.303352</td>\n",
       "      <td>-0.125460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.550872</td>\n",
       "      <td>-0.206212</td>\n",
       "      <td>0.986381</td>\n",
       "      <td>0.195744</td>\n",
       "      <td>0.775926</td>\n",
       "      <td>-0.364070</td>\n",
       "      <td>0.416320</td>\n",
       "      <td>-0.054803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.753976</td>\n",
       "      <td>-0.356303</td>\n",
       "      <td>-0.355062</td>\n",
       "      <td>-0.303112</td>\n",
       "      <td>0.957206</td>\n",
       "      <td>-0.357341</td>\n",
       "      <td>0.194543</td>\n",
       "      <td>-0.174749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.107599</td>\n",
       "      <td>1.527975</td>\n",
       "      <td>0.307792</td>\n",
       "      <td>-0.145344</td>\n",
       "      <td>-0.704399</td>\n",
       "      <td>-0.158774</td>\n",
       "      <td>0.735482</td>\n",
       "      <td>-0.117141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  1.005661 -0.383383 -0.594069  0.071181 -0.250360  0.125830 -0.339176   \n",
       "1  0.997704 -0.329294  0.353681 -0.444899 -0.176497 -0.192101  0.303352   \n",
       "2 -0.550872 -0.206212  0.986381  0.195744  0.775926 -0.364070  0.416320   \n",
       "3  0.753976 -0.356303 -0.355062 -0.303112  0.957206 -0.357341  0.194543   \n",
       "4  1.107599  1.527975  0.307792 -0.145344 -0.704399 -0.158774  0.735482   \n",
       "\n",
       "          8  \n",
       "0  0.077826  \n",
       "1 -0.125460  \n",
       "2 -0.054803  \n",
       "3 -0.174749  \n",
       "4 -0.117141  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtp=pc.fit_transform(scaled_dft)\n",
    "xpct=pd.DataFrame(dtp,columns=['1','2','3','4','5','6','7','8'])\n",
    "xpct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1107ae92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: income, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f5c26379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6216380952380952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.62      0.77    105000\n",
      "\n",
      "    accuracy                           0.62    105000\n",
      "   macro avg       0.50      0.31      0.38    105000\n",
      "weighted avg       1.00      0.62      0.77    105000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(xpc,y)\n",
    "ypred=lr.predict(xpc)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5d97e8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9099809523809523\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.97      0.87     32306\n",
      "           1       0.98      0.88      0.93     72694\n",
      "\n",
      "    accuracy                           0.91    105000\n",
      "   macro avg       0.89      0.93      0.90    105000\n",
      "weighted avg       0.92      0.91      0.91    105000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "rf.fit(xpc,y)\n",
    "ypred=rf.predict(xpc)\n",
    "print(accuracy_score(ypred,y))\n",
    "print(classification_report(ypred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5c2cd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1=rf.predict(xpct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8988451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypp=pd.DataFrame(ypred1)\n",
    "ypp.to_csv('7yp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d21fa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "39044d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([\n",
    "    layers.Dense(18,input_shape=(18,),activation='relu'),\n",
    "    layers.Dense(100,activation='relu'),\n",
    "    layers.Dense(1,activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='SGD',loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f7ef7f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3282/3282 [==============================] - 10s 3ms/step - loss: 0.6618 - accuracy: 0.6193\n",
      "Epoch 2/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6588 - accuracy: 0.6217\n",
      "Epoch 3/20\n",
      "3282/3282 [==============================] - 8s 2ms/step - loss: 0.6579 - accuracy: 0.6224\n",
      "Epoch 4/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6573 - accuracy: 0.6239\n",
      "Epoch 5/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6567 - accuracy: 0.6257\n",
      "Epoch 6/20\n",
      "3282/3282 [==============================] - 8s 2ms/step - loss: 0.6561 - accuracy: 0.6281\n",
      "Epoch 7/20\n",
      "3282/3282 [==============================] - 12s 4ms/step - loss: 0.6556 - accuracy: 0.6292\n",
      "Epoch 8/20\n",
      "3282/3282 [==============================] - 9s 3ms/step - loss: 0.6550 - accuracy: 0.6312\n",
      "Epoch 9/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6546 - accuracy: 0.6324\n",
      "Epoch 10/20\n",
      "3282/3282 [==============================] - 6s 2ms/step - loss: 0.6541 - accuracy: 0.6325\n",
      "Epoch 11/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6539 - accuracy: 0.6333\n",
      "Epoch 12/20\n",
      "3282/3282 [==============================] - 9s 3ms/step - loss: 0.6535 - accuracy: 0.6332\n",
      "Epoch 13/20\n",
      "3282/3282 [==============================] - 9s 3ms/step - loss: 0.6532 - accuracy: 0.6335\n",
      "Epoch 14/20\n",
      "3282/3282 [==============================] - 9s 3ms/step - loss: 0.6529 - accuracy: 0.6341\n",
      "Epoch 15/20\n",
      "3282/3282 [==============================] - 8s 2ms/step - loss: 0.6527 - accuracy: 0.6345\n",
      "Epoch 16/20\n",
      "3282/3282 [==============================] - 7s 2ms/step - loss: 0.6525 - accuracy: 0.6345\n",
      "Epoch 17/20\n",
      "3282/3282 [==============================] - 6s 2ms/step - loss: 0.6524 - accuracy: 0.6346\n",
      "Epoch 18/20\n",
      "3282/3282 [==============================] - 8s 3ms/step - loss: 0.6520 - accuracy: 0.6352\n",
      "Epoch 19/20\n",
      "3282/3282 [==============================] - 8s 3ms/step - loss: 0.6520 - accuracy: 0.6340\n",
      "Epoch 20/20\n",
      "3282/3282 [==============================] - 8s 2ms/step - loss: 0.6519 - accuracy: 0.6350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2103d0ebbb0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xbefe,y,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9cb2d6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "ypred=model.predict(xtbefe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ee552845",
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded=[np.round(x[0]) for x in ypred]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
